# 7주차 - 웹 크롤러 설계

## 사전질문

> 웹 크롤러의 시작 URL 집합을 어떻게 고르시겠습니까?
  - 미수집 URL 저장소를 어떻게 관리하시겠습니까?
  - 이미 방문한 URL이나 미수집 URL 저장소에 보관된 URL을 추적할 수 있도록 하는 자료구조로 블룸 필터나 해시 테이블이 널리 쓰입니다.
    블룸 필터와 해시테이블에 대해 간단하게 설명해주세요.

<br>

> 예의 바른 크롤러를 만들기 위해선, 동일 웹 사이트에 대해서는 한 번에 한 페이지만 요청해야 합니다.   
그렇게 하기 위해 같은 웹 사이트의 페이지를 다운받는 태스크를 시간차를 두고 실행하면 됩니다.
이러한 요구사항을 만족시기 위한 조건으로 무엇이 있을까요?
  - 웹사이트의 호스트명과 다운로드를 수행하는 작업 스레드 사이의 관계를 유지하기 위해선,
    스레드별로 어떤 자료구조를 가지면 될까요?
  - 해당 큐에서 꺼낸 URL만 다운로드하기 위해 어떤 방법들로 어떻게 설계하실건가요?

<br>

> 대규모 웹사이트 데이터를 수집하기 위한 분산 웹 크롤러의 전반적인 아키텍처를 어떻게 구성할 것인지 설계 방안을 제시해주세요.   
    (힌트: 서버 간의 데이터 동기화, 크롤링 작업 분배, 네트워크 트래픽 관리)
  - 분산된 크롤링 시스템에서 URL 중복을 효과적으로 처리하기 위한 전략으로 어떤게 있을까요?   
    (힌트: URL 해싱, 공유 데이터베이스 사용, 중복 감지 로직)   
  - 웹 크롤러는 대상 웹사이트에 부하를 주지 않도록 요청 속도를 조절해야 합니다.   
   요청 속도 조절을 위해 어떤 것을 참고하면 좋을까요?
